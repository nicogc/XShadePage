<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="The Green Canvas : Art evaluation analytics">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>XShadePage</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/nicogc/crossshade">View on GitHub</a>

          <h1 id="project_title">Welcome to XShadePage </h1>
          <h2 id="project_tagline">CrossShade: Shading concept sketches using cross-section curves - Replication</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/nicogc/crossshade/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/nicogc/crossshade/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="data-science-cs109-final-project---fall-2014" class="anchor" href="#data-science-cs109-final-project---fall-2014" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computer Graphics CS109 Final Project </h3>

<h4>
<a id="ahmed-hosny-jili-huang-yingyi-wang" class="anchor" href="#ahmed-hosny-jili-huang-yingyi-wang" aria-hidden="true"><span class="octicon octicon-link"></span></a>Nicolás Gutierrez Castilla</h4>

<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KoNN6Ii-3r4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> 

<!--<p><a href="https://www.youtube.com/watch?v=KoNN6Ii-3r4">The Green Canvas: Art Valuation Analytics</a> from <a href="http://vimeo.com/user22774474">yingyi</a> on <a href="https://youtube.com">Youtube</a>.</p>-->
<br>
<h3>
<a id="background-and-motivation" class="anchor" href="#background-and-motivation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h3>

<p>CrossShade allows the creation of 3D-looking shaded production drawings from concept sketches. We use artist-drawn cross-section lines to automatically infer surface information across the sketch, enabling 3D-like rendering. </p>


<h3>
<a id="background-and-motivation" class="anchor" href="#background-and-motivation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resumen</h3>

<p>El paper trata de dar un renderizado con estilo 3D a sketches usando unas curvas usadas en los sketches llamadas curvas de corte de seccion o CrossSection Curves, usando estar curvas y algunas restricciones se puede determinar las normales en el sketch con las cuales se podr dar un shading adecuado para dar el efecto de 3D.</p>

<!--
<h3>
<a id="project-objectives" class="anchor" href="#project-objectives" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Objectives</h3>

<p>This project aims at studying art valuation criterion with a specific focus on paintings. While the art market itself is responsible for fluctuations and trends, aesthetics plays an important role in evaluating art pieces. Image processing will be utilized to extract pixel information and attempt to correlate these with the peices' current market value. Therefore, the plan is to:</p>

<ul>
<li>Use data to explore trends in painting evaluation. How is information about the painting or even at the pixel level influencing evaluation?</li>
<li>Develop a machine learning framework that can predict pricing. Can we develop an algorithm that can replace expert art consultants and can be used by, say, auction houses?</li>
</ul>
-->
<h3>
<a id="data-acquisition" class="anchor" href="#data-acquisition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduccion</h3>

<p>El paper se divide en 2 partes principales, la primera es encontrar las normales en los puntos de interseccion ́ de los CrossSections y la segunda es propagar esa normal alrededor de la curva y todo el sketch.</p>


<!--
<ul>
<li>Internet: Scrape information off websites such as <a href="http://artsalesindex.artinfo.com/asi/lots/3426445">http://artsalesindex.artinfo.com/asi/lots/3426445</a> . A Pandas dataframe will be constructed containing the columns: Artist's name, Year, Country, Painting Name, Style, Material, size, Markings and Price with time sold.</li>
<li>Image of the painting itself: Use openCV and PIL libraries to add features to the dataframe such as: Face detection - tell us whether it is a portrait or not, Top dominant colors, large/small Areas of solid color, Edges, contrast, brightness, hue, saturation…</li>
</ul>
-->


<h3>
<a id="design-overview" class="anchor" href="#design-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algoritmo</h3>
<hr>
<h4>
<a id="source" class="anchor" href="#source" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problema de Minimización</h4>

<p>Para hallar las normales en los puntos de interseccion ́ entre cross sections, se intenta minimizar la función para determinar la tercera componente de la tangente en el punto donde se cruzan las curvas de corte de sección y hallar los valores de las normales correspondientes a los planos 3D que contienen a cada una de las curvas de corte de sección.</p>

<h4>
<a id="source" class="anchor" href="#source" aria-hidden="true"><span class="octicon octicon-link"></span></a>Propagación de la Normal</h4>

<ul>
<li>La región esta encerrada por 4 curvas de corte de sección.</li>
<li>Se estima una grilla en esta región</li>
<li>Por ultimo se utiliza una interpolacion coons en la grilla estimada.</li>
</ul>

<!--
<ul>
<li>Explore trends by grouping by artist, location, material and so on. Which material or style cost the most? Or some interesting discovery such as which size of the drawings would be most expensive in terms of unit area. These will be based on pandas dataframe manipulation and grouping. We will also attempt to reduce dimentionality of the data and explore the principal components.</li>
<li>After pixel information is added to the dataframe, stage one will be repeated to explore additional trends</li>
<li>Build a ML model that is able to predict value. Explore different ML techniques learned in class and which is more appropriate for our application. Which feature is most influential on the evaluation?</li>
</ul>
-->


<hr>

<h3>
<a id="data-scraping" class="anchor" href="#data-scraping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementación</h3>


<h4>
<a id="source" class="anchor" href="#source" aria-hidden="true"><span class="octicon octicon-link"></span></a>Leer Cross Sections Curves</h4>

<p>En el paper utilizan herramientas de dibujo vecto- riales estndar, asi que para las curvas que se dibujan

pixel a pixel trato de aproximar una curva de bezier cubica que minimice la distancia entre esta curva y los pixeles de la curva y remplazo los pixeles pintados con la nueva curva de bezier B(t).</p>

<h4>
<a id="source" class="anchor" href="#source" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resolver el problema de minimización</h4>

<p>Ahora que tenemos las curvas en ya no en pixeles sino en funcin a una curva de bezier podemos saber si dos curvas se cruzan y en que parametro t, también podemos derivar la funcion de la curva para obtener las ́ tangentes en esos puntos, pero solo los componentes (x,y). Para la optimizacion de la función ́ 1 utilice la librería nlopt, y como era una sumatoria al cuadrado, utilice el metodo de optimización LN_COBYLA que no utiliza la gradiente de la funcion para poder optimizarla.</p>


<h3>
<a id="data-scraping" class="anchor" href="#data-scraping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusiones</h3>
<p>Una de las partes más importantes del paper es encontrar las normales en los puntos de interseccion entre cross sections curves (Cross Hairs), asi que ahora falta propagar las normales por el sketch.</p>
<a id="data-scraping" class="anchor" href="#data-scraping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Codigo</h3>
<p>Code Available on <a href="https://github.com/nicogc/crossshade">Github</a></p>


<!--
<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/front%20page.jpg" alt=""></p>

<h4>
<a id="part-1-create-dataframe" class="anchor" href="#part-1-create-dataframe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Part 1 Create Dataframe</h4>

<p>To get access to information about each paintings, we actually make a 3-step subsequent query using beautifulsoup</p>

<h5>
<a id="step-1" class="anchor" href="#step-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>step 1</h5>

<p>Using artists' name (alphabet order) - Take 'A' as an example, the url '<a href="http://artsalesindex.artinfo.com/asi/search/artistsAtoZ.ai?lastName=A&amp;startRowNum=">http://artsalesindex.artinfo.com/asi/search/artistsAtoZ.ai?lastName=A&amp;startRowNum=</a>' allows access to the artist's paintings. From here we create a list of all url's to their works.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/dataScraping%20Page1.jpg" alt=""></p>

<h5>
<a id="step-2" class="anchor" href="#step-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>step 2</h5>

<p>From each of the url above we come to the booklet of each artists. Here we collect the url's to each individual paintings.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/dataScraping%20Page2.jpg" alt=""></p>

<h5>
<a id="step-3" class="anchor" href="#step-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>step 3</h5>

<p>Finally we have arrive to the info page for each of these artworks. We create our dataframe from these pages.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/dataScraping%20Page3.jpg" alt=""></p>

<h4>
<a id="part-2-data-joining-and-cleaning" class="anchor" href="#part-2-data-joining-and-cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Part 2 Data joining and cleaning</h4>

<p>From the dataframe we notice there is some inconsistency and missing fields. Our next step is to join the data set and filter out missing field data. The dataframe looks something like this.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/0DATAFRAME.png" alt=""></p>
-->
<hr>

<hr>
<!--
<h3>
<a id="image-processing" class="anchor" href="#image-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image processing</h3>

<h4>
<a id="sample-image" class="anchor" href="#sample-image" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sample Image</h4>

<p>A single image will be used to illustrate the different image processing techniques used in the analysis.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/01Sample.png" alt=""></p>

<h4>
<a id="most-dominant-colors" class="anchor" href="#most-dominant-colors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Most Dominant Colors</h4>

<p>This function returns the hue of the most dominant color in the image. It first creates a predefined number of clusters from the RGB values in the image array. A larger number of clusters produces a more accurate result but is computationally more expensive. It then assigns codes to each item in the newly clustered array. A histogram counts the number of occurrences of each code. The RGB value that has the highest number of occurrences is the most dominant in the image.
A post-processing step is required here. The RGB value of the most dominant color is converted into HSL (hue,saturation, lightness). Thresholding is then used to assign each color to a bucket from the following: blacks, whites, grays, reds, yellows, greens, cyans, blues, magentas, reds</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/02Major%20Colors.png" alt=""></p>

<h4>
<a id="unique-color-ratio" class="anchor" href="#unique-color-ratio" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unique Color Ratio</h4>

<p>This function calculates the number of unique colors in an image as a ration of the total number of pixels. A list of color values across the image is generated. Duplicates are removed and the length of the duplicate-free list is calculated and divded by total number of pixels. If the result is close to 0, the image has very few unique colors i.e. large areas of one solid color. If the result is close to 1, the image is very colorful as every pixel has its own unique color. A 0 result indicates a grayscale image.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/03RGB.png" alt=""></p>

<h4>
<a id="image-thresholding" class="anchor" href="#image-thresholding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Thresholding</h4>

<p>Here, we apply a thresholding to the image. If pixel value is greater than a threshold value(here we use 127, range from 0-255), it is assigned one value (255,white), else it is assigned another value (0,black). Then we calculate the Percentage of white or black in the image, so we can get the ratio of black pixels in the greyscale of paintings.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/04GrayScale.png" alt=""></p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/05Thresheld.png" alt=""></p>

<h4>
<a id="relative-high-and-low-brightness-ratio" class="anchor" href="#relative-high-and-low-brightness-ratio" aria-hidden="true"><span class="octicon octicon-link"></span></a>Relative High and low Brightness Ratio</h4>

<p>We calculate the average brightness of each paintings here. Then we counts how many pixels have two times of the average brightness and how many pixels have less than half of the mean brightness of that image. So we can get the ratio of these two relatively values of each image. Because different from the mean brightness of overall image, sometimes we say this image has brightness because it has more higher ratio of bright pixels compare to the low pixels. We may get the feeling by comparison. One image has average of 100 brightness but has very low std does not feel more bright than a painting with 90 brightness but has a higher std.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/06brightness.png" alt=""></p>

<h4>
<a id="harris-corner-detection" class="anchor" href="#harris-corner-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Harris Corner Detection</h4>

<p>We use Harris Corner Detection to detect the corner in the paiting. Corner is the intersection of two edges, it represents a point in which the directions of these two edges change. Hence, the gradient of the image (in both directions) have a high variation, which can be used to detect it. With that, we can calcluate the ration of pixels as corners in the full image.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/07CornerDetection.png" alt=""></p>

<h4>
<a id="canny-edge-detection" class="anchor" href="#canny-edge-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Canny Edge Detection</h4>

<p>This function use Canny Edge Detection algorithm to detect the edges in the image. And then calculate the percentage of pixels recognized as edges in the whole picture.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/08Edge%20Detection.png" alt=""></p>

<h4>
<a id="haar-cascade-face-detection" class="anchor" href="#haar-cascade-face-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Haar-cascade Face Detection</h4>

<p>We use Haar-cascade Detection in OpenCV to detect the face in paintings. With that, we could know whether this looks like a portrait in a way. Because in contemporary paintings, it is hard to understand the image. Portrait does not necessarily means a portrait. We want to test for a paintings which is somewhat readable as human or face will have different influence on the price. We load haarcascade_frontalface_default as XML classifiers. It will show how many faces are detected in the paintings.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/09FaceDetection.png" alt=""></p>

<h4>
<a id="dataframe-integration" class="anchor" href="#dataframe-integration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataframe integration</h4>

<p>The output from all these routines is then stored into the previously created dataframe.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/10DataWithImageProcessing.png" alt=""></p>
-->
<hr>

<hr>
<!--
<h4>
<a id="we-analyzed-35407-paintings-at-a-total-valuation-of-9366754845-prices-included-a-maximum-of-119922500-an-average-of-264545-and-a-minimum-of-3" class="anchor" href="#we-analyzed-35407-paintings-at-a-total-valuation-of-9366754845-prices-included-a-maximum-of-119922500-an-average-of-264545-and-a-minimum-of-3" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"We analyzed 35407 paintings at a total valuation of $9,366,754,845. Prices included a maximum of $119,922,500, an average of $264,545 and a minimum of $3"</em>
</h4>
-->
<hr>

<hr>
<!--
<h3>
<a id="trends" class="anchor" href="#trends" aria-hidden="true"><span class="octicon octicon-link"></span></a>Trends</h3>

<h4>
<a id="paintings-produced-in-the-1960s-recorded-the-highest-salesthis-coincides-with-the-many-artistic-impulses-that-began-to-gain-momentum-during-that-period-including-the-explosion-of-consumerism-and-popular-culture" class="anchor" href="#paintings-produced-in-the-1960s-recorded-the-highest-salesthis-coincides-with-the-many-artistic-impulses-that-began-to-gain-momentum-during-that-period-including-the-explosion-of-consumerism-and-popular-culture" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"Paintings produced in the 1960's recorded the highest sales.This coincides with the many artistic impulses that began to gain momentum during that period including the explosion of consumerism and popular culture."</em>
</h4>

<p>Below is a comparison of prices aggregated per year with and without Andy Warhol.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/12PricePerYearwihAndy.png" alt=""></p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/13PricePerYearwihoutAndyUpdate.png" alt=""></p>

<h4>
<a id="paintings-with-whites-grays-and-blacks-as-dominant-colors-are-most-likely-to-have-high-sales-values-compared-to-other-more-saturated-colors" class="anchor" href="#paintings-with-whites-grays-and-blacks-as-dominant-colors-are-most-likely-to-have-high-sales-values-compared-to-other-more-saturated-colors" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"Paintings with whites, grays and blacks as dominant colors are most likely to have high sales values, compared to other more saturated colors"</em>
</h4>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/14PricePerDominantColorsCombine.png" alt=""></p>

<h4>
<a id="paintings-where-low-corner-percentages-are-detected-are-also-more-likely-to-have-high-sales-values" class="anchor" href="#paintings-where-low-corner-percentages-are-detected-are-also-more-likely-to-have-high-sales-values" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"Paintings where low corner percentages are detected are also more likely to have high sales values."</em>
</h4>

<p>Below are corner percentages grouped by three artist bands: master, famous and non famous. 9 artists that had large deviation are the plotted separately.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/15CornerPercentageGroupby.png" alt="">
<img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/17CornerPercentageArtist.png" alt=""></p>

<h4>
<a id="auction-of-very-valuable-pieces-tend-to-coincide-with-successful-exhibitions" class="anchor" href="#auction-of-very-valuable-pieces-tend-to-coincide-with-successful-exhibitions" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"Auction of very valuable pieces tend to coincide with successful exhibitions."</em>
</h4>

<p>From these famous artists's principles we've found an interesting feature. They tend to have very high peak at certain time. After research we realize all these moments they have run a very successful exhibition (eg: the Grand Opening of Mark Rothko Art Centre at 2006, Paul Cezanne exhibition 2013 the Museum of Fine Arts in Budapest ...). Then some masterpiece will be on auction. It is very likely that the media advertisement and public exhibition work together to attract attention first, then some really valuable art work will be sold.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/18famousPart%20(1).jpg" alt=""></p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/19famousPart%20(2).jpg" alt=""></p>
-->
<hr>

<hr>
<!--
<h3>
<a id="machine-learning" class="anchor" href="#machine-learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning</h3>

<p>In an attempt to develop a machine learning platform for pricing artwork, we created a linear regression model specifically fit for paintings by Spanish painter Pablo Picasso. We used a set of 4000 paintings for training and another equal set for testing. Our model reached a  predicted prices/actual prices correlation of 0.58. Using a single log on the price value gave the most optimum results.</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/Pablo%20Picasso.jpg" alt=""></p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/21Correlation.png" alt=""></p>

<p>We also built separate regression models based on single parameters as predictors. We noticed that the ratio of unique colors alone generated a relatively high correlation of 0.46 between predicted prices and actual prices. </p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/22Parameter.png" alt=""></p>

<p>This allowed us to pick the best performing parametrs for our regression model. The final version of the model scored  between 0.32 and 0.34</p>

<p><img src="https://raw.githubusercontent.com/ahmedhosny/theGreenCanvas/gh-pages/images/23finalmachinelearning.png" alt=""></p>
-->
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">The Green Canvas maintained by <a href="https://github.com/ahmedhosny">ahmedhosny</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
